Metadata-Version: 2.1
Name: compress-gpt
Version: 0.1.2
Summary: Self-extracting GPT prompts for ~70% token savings.
License: MIT
Author: Yasyf Mohamedali
Author-email: yasyfm@gmail.com
Requires-Python: >=3.10,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Dist: aiocache (>=0.12.0,<0.13.0)
Requires-Dist: dill (>=0.3.6,<0.4.0)
Requires-Dist: dirtyjson (>=1.0.8,<2.0.0)
Requires-Dist: hiredis (>=2.2.2,<3.0.0)
Requires-Dist: jinja2 (>=3.1.2,<4.0.0)
Requires-Dist: langchain (>=0.0.132,<0.0.133)
Requires-Dist: nest-asyncio (>=1.5.6,<2.0.0)
Requires-Dist: nltk (>=3.8.1,<4.0.0)
Requires-Dist: openai (>=0.27.4,<0.28.0)
Requires-Dist: pydantic (>=1.10.7,<2.0.0)
Requires-Dist: redis (>=4.5.4,<5.0.0)
Requires-Dist: rich (>=13.3.3,<14.0.0)
Requires-Dist: tiktoken (>=0.3.3,<0.4.0)
Description-Content-Type: text/markdown

# CompressGPT
## Self-extracting GPT prompts for ~70% token savings

Check out the accompanying blog post [here](https://musings.yasyf.com/compressgpt-decrease-token-usage-by-70/).

### Installation

```shell
$ pip install compress-gpt
```

### Usage

Simply change your existing imports of `langchain.PromptTemplate` to `compress_gpt.langchain.CompressTemplate` (to compress prompts before populating variables) or `compress_gpt.langchain.CompressPrompt` (to compress prompts after populating variables).

```diff
-from langchain import PromptTemplate
+from compress_gpt.langchain import CompressPrompt as PromptTemplate
```

For very simple prompts, use `CompressSimplePrompt` and `CompressSimpleTemplate` instead.

If compression ever fails or results in extra tokens, the original prompt will be used. Each compression result is aggressively cached, but the first run can take a hot sec.

#### Clearing the cache

```python
import compress_gpt

compress_gpt.clear_cache()
```

### Demo

[![asciicast](https://asciinema.org/a/578285.svg)](https://asciinema.org/a/578285)


### How CompressGPT Works

My [blog post](https://musings.yasyf.com/compressgpt-decrease-token-usage-by-70/) helps explain the below image.

![CompressGPT Pipeline](assets/pipeline.svg)

