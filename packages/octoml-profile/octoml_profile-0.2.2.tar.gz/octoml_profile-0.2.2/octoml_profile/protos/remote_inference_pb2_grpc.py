# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc

from octoml_profile.protos import inference_base_pb2 as octoml__profile_dot_protos_dot_inference__base__pb2
from octoml_profile.protos import remote_inference_pb2 as octoml__profile_dot_protos_dot_remote__inference__pb2


class RemoteInferenceStub(object):
    """--- RemoteInference ----------------------------

    """

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.Ping = channel.unary_unary(
                '/octoml_profile.RemoteInference/Ping',
                request_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.PingRequest.SerializeToString,
                response_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.PingReply.FromString,
                )
        self.ListSupportedBackends = channel.unary_unary(
                '/octoml_profile.RemoteInference/ListSupportedBackends',
                request_serializer=octoml__profile_dot_protos_dot_remote__inference__pb2.ListSupportedBackendsRequest.SerializeToString,
                response_deserializer=octoml__profile_dot_protos_dot_remote__inference__pb2.ListSupportedBackendsReply.FromString,
                )
        self.CreateSession = channel.unary_unary(
                '/octoml_profile.RemoteInference/CreateSession',
                request_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.CreateSessionRequest.SerializeToString,
                response_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.CreateSessionReply.FromString,
                )
        self.WaitUntilSessionReady = channel.unary_unary(
                '/octoml_profile.RemoteInference/WaitUntilSessionReady',
                request_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.WaitUntilSessionReadyRequest.SerializeToString,
                response_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.WaitUntilSessionReadyReply.FromString,
                )
        self.Heartbeat = channel.unary_unary(
                '/octoml_profile.RemoteInference/Heartbeat',
                request_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.HeartbeatRequest.SerializeToString,
                response_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.HeartbeatReply.FromString,
                )
        self.CloseSession = channel.unary_unary(
                '/octoml_profile.RemoteInference/CloseSession',
                request_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.CloseSessionRequest.SerializeToString,
                response_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.CloseSessionReply.FromString,
                )
        self.LoadModelComponent = channel.stream_unary(
                '/octoml_profile.RemoteInference/LoadModelComponent',
                request_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.LoadModelComponentRequest.SerializeToString,
                response_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.LoadModelComponentReply.FromString,
                )
        self.LoadCachedModelComponent = channel.unary_unary(
                '/octoml_profile.RemoteInference/LoadCachedModelComponent',
                request_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.LoadCachedModelComponentRequest.SerializeToString,
                response_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.LoadCachedModelComponentReply.FromString,
                )
        self.LoadModel = channel.unary_unary(
                '/octoml_profile.RemoteInference/LoadModel',
                request_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.LoadModelRequest.SerializeToString,
                response_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.LoadModelReply.FromString,
                )
        self.Run = channel.unary_unary(
                '/octoml_profile.RemoteInference/Run',
                request_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.RunRequest.SerializeToString,
                response_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.RunReply.FromString,
                )


class RemoteInferenceServicer(object):
    """--- RemoteInference ----------------------------

    """

    def Ping(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def ListSupportedBackends(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def CreateSession(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def WaitUntilSessionReady(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def Heartbeat(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def CloseSession(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def LoadModelComponent(self, request_iterator, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def LoadCachedModelComponent(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def LoadModel(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def Run(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_RemoteInferenceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'Ping': grpc.unary_unary_rpc_method_handler(
                    servicer.Ping,
                    request_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.PingRequest.FromString,
                    response_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.PingReply.SerializeToString,
            ),
            'ListSupportedBackends': grpc.unary_unary_rpc_method_handler(
                    servicer.ListSupportedBackends,
                    request_deserializer=octoml__profile_dot_protos_dot_remote__inference__pb2.ListSupportedBackendsRequest.FromString,
                    response_serializer=octoml__profile_dot_protos_dot_remote__inference__pb2.ListSupportedBackendsReply.SerializeToString,
            ),
            'CreateSession': grpc.unary_unary_rpc_method_handler(
                    servicer.CreateSession,
                    request_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.CreateSessionRequest.FromString,
                    response_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.CreateSessionReply.SerializeToString,
            ),
            'WaitUntilSessionReady': grpc.unary_unary_rpc_method_handler(
                    servicer.WaitUntilSessionReady,
                    request_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.WaitUntilSessionReadyRequest.FromString,
                    response_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.WaitUntilSessionReadyReply.SerializeToString,
            ),
            'Heartbeat': grpc.unary_unary_rpc_method_handler(
                    servicer.Heartbeat,
                    request_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.HeartbeatRequest.FromString,
                    response_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.HeartbeatReply.SerializeToString,
            ),
            'CloseSession': grpc.unary_unary_rpc_method_handler(
                    servicer.CloseSession,
                    request_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.CloseSessionRequest.FromString,
                    response_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.CloseSessionReply.SerializeToString,
            ),
            'LoadModelComponent': grpc.stream_unary_rpc_method_handler(
                    servicer.LoadModelComponent,
                    request_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.LoadModelComponentRequest.FromString,
                    response_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.LoadModelComponentReply.SerializeToString,
            ),
            'LoadCachedModelComponent': grpc.unary_unary_rpc_method_handler(
                    servicer.LoadCachedModelComponent,
                    request_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.LoadCachedModelComponentRequest.FromString,
                    response_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.LoadCachedModelComponentReply.SerializeToString,
            ),
            'LoadModel': grpc.unary_unary_rpc_method_handler(
                    servicer.LoadModel,
                    request_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.LoadModelRequest.FromString,
                    response_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.LoadModelReply.SerializeToString,
            ),
            'Run': grpc.unary_unary_rpc_method_handler(
                    servicer.Run,
                    request_deserializer=octoml__profile_dot_protos_dot_inference__base__pb2.RunRequest.FromString,
                    response_serializer=octoml__profile_dot_protos_dot_inference__base__pb2.RunReply.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'octoml_profile.RemoteInference', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


 # This class is part of an EXPERIMENTAL API.
class RemoteInference(object):
    """--- RemoteInference ----------------------------

    """

    @staticmethod
    def Ping(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/octoml_profile.RemoteInference/Ping',
            octoml__profile_dot_protos_dot_inference__base__pb2.PingRequest.SerializeToString,
            octoml__profile_dot_protos_dot_inference__base__pb2.PingReply.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def ListSupportedBackends(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/octoml_profile.RemoteInference/ListSupportedBackends',
            octoml__profile_dot_protos_dot_remote__inference__pb2.ListSupportedBackendsRequest.SerializeToString,
            octoml__profile_dot_protos_dot_remote__inference__pb2.ListSupportedBackendsReply.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def CreateSession(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/octoml_profile.RemoteInference/CreateSession',
            octoml__profile_dot_protos_dot_inference__base__pb2.CreateSessionRequest.SerializeToString,
            octoml__profile_dot_protos_dot_inference__base__pb2.CreateSessionReply.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def WaitUntilSessionReady(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/octoml_profile.RemoteInference/WaitUntilSessionReady',
            octoml__profile_dot_protos_dot_inference__base__pb2.WaitUntilSessionReadyRequest.SerializeToString,
            octoml__profile_dot_protos_dot_inference__base__pb2.WaitUntilSessionReadyReply.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def Heartbeat(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/octoml_profile.RemoteInference/Heartbeat',
            octoml__profile_dot_protos_dot_inference__base__pb2.HeartbeatRequest.SerializeToString,
            octoml__profile_dot_protos_dot_inference__base__pb2.HeartbeatReply.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def CloseSession(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/octoml_profile.RemoteInference/CloseSession',
            octoml__profile_dot_protos_dot_inference__base__pb2.CloseSessionRequest.SerializeToString,
            octoml__profile_dot_protos_dot_inference__base__pb2.CloseSessionReply.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def LoadModelComponent(request_iterator,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.stream_unary(request_iterator, target, '/octoml_profile.RemoteInference/LoadModelComponent',
            octoml__profile_dot_protos_dot_inference__base__pb2.LoadModelComponentRequest.SerializeToString,
            octoml__profile_dot_protos_dot_inference__base__pb2.LoadModelComponentReply.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def LoadCachedModelComponent(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/octoml_profile.RemoteInference/LoadCachedModelComponent',
            octoml__profile_dot_protos_dot_inference__base__pb2.LoadCachedModelComponentRequest.SerializeToString,
            octoml__profile_dot_protos_dot_inference__base__pb2.LoadCachedModelComponentReply.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def LoadModel(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/octoml_profile.RemoteInference/LoadModel',
            octoml__profile_dot_protos_dot_inference__base__pb2.LoadModelRequest.SerializeToString,
            octoml__profile_dot_protos_dot_inference__base__pb2.LoadModelReply.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def Run(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/octoml_profile.RemoteInference/Run',
            octoml__profile_dot_protos_dot_inference__base__pb2.RunRequest.SerializeToString,
            octoml__profile_dot_protos_dot_inference__base__pb2.RunReply.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
