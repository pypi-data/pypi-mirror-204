model:
  model_config:
    type: BertConfig
    use_one_hot_embeddings: False
    num_labels: 3
    dropout_prob: 0.1
    batch_size: 64
    seq_length: 128
    vocab_size: 30522
    embedding_size: 768
    num_layers: 12
    num_heads: 12
    expand_ratio: 4
    hidden_act: "gelu"
    post_layernorm_residual: True
    hidden_dropout_prob: 0.1
    attention_probs_dropout_prob: 0.1
    max_position_embeddings: 512
    type_vocab_size: 2
    initializer_range: 0.02
    use_relative_positions: False
    use_past: False
    compute_dtype: "float32"
    checkpoint_name_or_path: "txtcls_bert_base_uncased"
  arch:
    type: BertForMultipleChoice

processor:
  return_tensors: ms
  tokenizer:
    cls_token: '[CLS]'
    do_basic_tokenize: True
    do_lower_case: True
    mask_token: '[MASK]'
    pad_token: '[PAD]'
    sep_token: '[SEP]'
    type: BertTokenizer
    unk_token: '[UNK]'
  type: BertProcessor