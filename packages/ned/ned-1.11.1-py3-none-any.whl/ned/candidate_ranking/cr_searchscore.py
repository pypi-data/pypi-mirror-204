from __future__ import annotations
import numpy as np
from ned.candidate_ranking.cr_dataset import CRDataset, NoCacheCRDataset
from ned.candidate_ranking.cr_method import (
    CandidateEntityScores,
    CandidateRankingMethod,
    ModelOutput,
)

from abc import ABC, abstractmethod
from pathlib import Path
from typing import Optional, Literal, overload
from ream.data_model_helper import NumpyDataModel
from ream.params_helper import NoParams

import torch
from torch.utils.data import DataLoader, Dataset

from ned.candidate_ranking.helpers.dataset import MyDataset
from ned.data_models.prelude import DatasetCandidateEntities, NEDExample
from tqdm import tqdm
from nptyping import Float64, NDArray, Shape, Object


class CRSearchScore(CandidateRankingMethod):
    """A candidate ranking method that does nothing but return the min-max normalized score from search engine"""

    VERSION = 101

    def forward(self, *args, **kwargs) -> ModelOutput:
        raise NotImplementedError("This method does not support training")

    def generate_dataset(
        self,
        examples: list[NEDExample],
        candidates: DatasetCandidateEntities,
        num_proc: Optional[int] = None,
        for_training: bool = False,
        cache_dir: Optional[Path] = None,
        return_candidates: bool = False,
    ) -> MyDataset | tuple[MyDataset, DatasetCandidateEntities]:
        ds = MyDataset([])
        if return_candidates:
            return ds, candidates
        return ds

    def get_generating_dataset_args(self) -> dict[str, str]:
        """Get arguments that are specific to the dataset generated by the model.
        Note this arguments should only affect the dataset customization part as we won't use it to generate a new caching directory"""
        return {}

    def rank_examples(
        self, examples: list[NEDExample], candidates: DatasetCandidateEntities
    ) -> CandidateEntityScores:
        return CandidateEntityScores(min_max_norm_candidate_scores(candidates))

    def rank_datasets(
        self,
        examples: list[NEDExample],
        candidates: DatasetCandidateEntities,
        dataset: Dataset,
        verbose: bool = False,
    ) -> CandidateEntityScores:
        return CandidateEntityScores(min_max_norm_candidate_scores(candidates))


def min_max_norm_candidate_scores(candidates: DatasetCandidateEntities):
    score = candidates.score.copy()
    for tid, (tstart, tend, tindex) in candidates.index.items():
        for ci, (cstart, cend, cindex) in tindex.items():
            for ri, (rstart, rend) in cindex.items():
                if rstart == rend:
                    continue
                score[rstart:rend] = min_max_norm(score[rstart:rend])
    return score


def min_max_norm(scores: np.ndarray):
    smin = scores.min()
    return (scores - smin) / max(scores.max() - smin, 1e-9)
