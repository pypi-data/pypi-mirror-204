from __future__ import annotations
from collections.abc import Sequence
import numpy as np
from ned.candidate_ranking.cr_dataset import CRDataset, NoCacheCRDataset
from ned.candidate_ranking.cr_method import (
    CandidateEntityScores,
    CandidateRankingMethod,
    ModelOutput,
)

from abc import ABC, abstractmethod
from pathlib import Path
from typing import Optional, Literal, overload, Union
from ream.data_model_helper import NumpyDataModel
from ream.params_helper import NoParams

import torch
from torch.utils.data import DataLoader, Dataset

from ned.candidate_ranking.helpers.dataset import MyDataset
from ned.data_models.prelude import DatasetCandidateEntities, NEDExample
from tqdm import tqdm
from nptyping import Float64, NDArray, Shape, Object
from dataclasses import dataclass, field


@dataclass
class CRStringSimilarityArgs:
    funcs: list[str] = field(
        default_factory=lambda: [],
        metadata={"help": "The functions to use for string similarity"},
    )
    func_scores: list[float] = field(
        default_factory=lambda: [1],
        metadata={
            "help": "The score of each function. If a single value array is provided, it will be used for all functions"
        },
    )


class CRStringSimilarity(CandidateRankingMethod):
    """A candidate ranking method that does nothing but return the min-max normalized score from search engine"""

    VERSION = 101

    def __init__(self, funcs: list[str], func_scores: list[float]):
        super().__init__()
        self.funcs = funcs
        self.func_scores = func_scores

        self.name2index = {
            "levenshtein": 0,
            "jaro_winkler": 1,
            "monge_elkan": 2,
            "sym_monge_elkan": 3,
            "hybrid_jaccard": 4,
            "numeric_sym_monge_elkan": 5,
            "numeric_hybrid_jaccard": 6,
            "alias_levenshtein": 7,
            "alias_jaro_winkler": 8,
            "alias_monge_elkan": 9,
            "alias_sym_monge_elkan": 10,
            "alias_hybrid_jaccard": 11,
            "alias_numeric_sym_monge_elkan": 12,
            "alias_numeric_hybrid_jaccard": 13,
            "all_levenshtein": 14,
            "all_jaro_winkler": 15,
            "all_monge_elkan": 16,
            "all_sym_monge_elkan": 17,
            "all_hybrid_jaccard": 18,
            "all_numeric_sym_monge_elkan": 19,
            "all_numeric_hybrid_jaccard": 20,
            "pagerank": 21,
        }

    @staticmethod
    def from_args(args: CRStringSimilarityArgs):
        if len(args.func_scores) > 1:
            func_scores = [float(x) for x in args.func_scores]
            assert len(func_scores) == len(args.funcs)
        else:
            func_scores = [args.func_scores[0]] * len(args.funcs)
        return CRStringSimilarity(args.funcs, func_scores)

    def forward(self, features, label=None) -> np.ndarray:
        probs = np.zeros((features.shape[0],), dtype=np.float64)
        for i, func in enumerate(self.funcs):
            probs += features[:, self.name2index[func]] * self.func_scores[i]
        probs = probs / sum(self.func_scores)

        assert is_valid_probs(probs)
        return probs

    def generate_dataset(
        self,
        examples: list[NEDExample],
        candidates: DatasetCandidateEntities,
        num_proc: Optional[int] = None,
        for_training: bool = False,
        cache_dir: Optional[Path] = None,
        return_candidates: bool = False,
    ) -> MyDataset | tuple[MyDataset, DatasetCandidateEntities]:
        crds = CRDataset(cache_dir) if cache_dir is not None else NoCacheCRDataset()

        provenance = ""
        crcan_base = crds.base_can(examples, candidates, provenance)
        crcan_features = crds.can_features(candidates, crcan_base, provenance)

        obj = {
            "features": crcan_features.features,
            "cell": crcan_base.cell_id,
        }
        ds = MyDataset(obj)
        if return_candidates:
            return ds, candidates
        return ds

    def get_generating_dataset_args(self) -> dict[str, str]:
        """Get arguments that are specific to the dataset generated by the model.
        Note this arguments should only affect the dataset customization part as we won't use it to generate a new caching directory"""
        return {}

    def rank_datasets(
        self,
        examples: list[NEDExample],
        candidates: DatasetCandidateEntities,
        dataset: Dataset,
        verbose: bool = False,
    ) -> CandidateEntityScores:
        assert isinstance(dataset, MyDataset)
        assert isinstance(dataset.examples, dict)
        return CandidateEntityScores(self.forward(dataset.examples["features"]))


def is_valid_probs(scores: np.ndarray):
    return np.all(scores >= 0) & np.all(1 >= scores)
