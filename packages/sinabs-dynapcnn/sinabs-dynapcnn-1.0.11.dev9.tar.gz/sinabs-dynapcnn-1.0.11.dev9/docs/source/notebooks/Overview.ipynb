{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of DYNAP-CNN and SPECK devlopment kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DYNAP-CNN and SPECK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DYNAP-CNN/SPECK are a family of spiking neural network ASICs family, which is designed to focusing on convolution spiking neural network(SCNN) based vision processing tasks. DYNAP-CNN is a fully scalable, event-driven neuromorphic processor with up to 0.32M configurable spiking neurons and direct interface with external DVS. Speckâ„¢ is the world first neuromorphic device which integrates the DYNAP-CNN neuromorphic processor and a dynamic vision sensor(DVS) into a single SoC.\n",
    "\n",
    "![image.png](../_static/Overview/speck_dynapcnn.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, __sinabs-dynapcnn__ library provides the interface to serveral available versions of hardwares for DYNAPCNN/SPECK family:\n",
    "\n",
    "| Device Name |Identifier |\n",
    "| :----| :----: | \n",
    "| DYNAP-CNN Development Kit |*dynapcnndevkit | \n",
    "| Speck Tiny Development Kit|*speck2btiny|\n",
    "| Speck Development Kit |*speck2edevkit|\n",
    "\n",
    "__note__: * stands for the correspond software identifier we assigned to the different devkit\n",
    "\n",
    "<br />\n",
    "\n",
    "The general top level diagram of the DYNAP-CNN/SPECK chip is shown as follows:\n",
    "\n",
    "![top_diagram](../_static/Overview/speck_top_level.png)\n",
    "\n",
    "\n",
    "For DYNAP-CNN dev-kits, it allows the user to interact with the chip using external DVS sensors or pre-defined event data. Speck seriers devkit based on above, it additionally allows the user to use its embeded internal DVS for development.\n",
    "\n",
    "Currently, Speck/Dynapcnn supports following External DVS sensor with the samna support:\n",
    "\n",
    "* Inivation Davis346\n",
    "* Inivation Davis240\n",
    "* Inivation DVXplorer\n",
    "* Prophesee EVK3-Gen 3.1VGA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Role of sinabs-dynapcnn Library\n",
    "\n",
    "To interact with these developmentkit, sinabs-dynapcnn needs [samna](https://pypi.org/project/samna/) dependency to enables the chip configuration and network setting. As is shown in the figure below, sinabs-dynapcnn is mainly targeting to provide an simple way to convert the network structure and parameters to the _sammnaconfiguration_ that can be used by samna to setup the chip. \n",
    "\n",
    "\n",
    "![sinab-dynapcnn](../_static/Overview/sinabs-dynapcnn-role.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chip Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all DYNAP-CNN/SPECK family, they using the DYNAP asynchronous computing structure and have the similar computation resources. The detailed features are shown below\n",
    "\n",
    "## Key Features\n",
    "\n",
    "* Async input interface: Speck devkit supports configure both from the internal dvs sensor or external dvs resources\n",
    "\n",
    "* Async output interface: 1: monitor bus output 2:readout layer output\n",
    "\n",
    "* Interrupt: 4 ouput pins encodes max 15 + 1(no class) output\n",
    "\n",
    "* 128x128 DVS array with every pixel can be configured to be killed\n",
    "\n",
    "* 1x  Event(For DVS) pre-processing layer\n",
    "* 9x  DYNAP-CNN Layer\n",
    "* 1x  Readout layer that can does the prediction based on DYNAP-CNN layer output \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Pre-processing Layer\n",
    "The event pre-processing layer receives the input events coming from dvs or an externa source. Depending on the configuration, the layer can perform following operations based on events:\n",
    "\n",
    "* Merge/Select the polarity of the input event stream\n",
    "* Sum Pool with kerlnel size of 1x1, 2x2, 4x4\n",
    "* ROI selection\n",
    "* Mirroring the event stream\n",
    "* Rotate 90 degrees\n",
    "\n",
    "An Event noise filter is also included in the pre-processing layer, the filter can be enabled upon users setting. A general pre-processing pipeline for the preprocessing pipe line is shown as follow:\n",
    "\n",
    "![image.png](../_static/Overview/event_preprocessing_pipeline.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DYNAP-CNN Layer\n",
    "\n",
    "The DYNAP-CNN Layer is the main hard ware representation of the designed spiking neural network structure. One of the main goal of the sinabs-dynapcnn is to provide an efficient, simply way to convert the `torch.Sequential` object to equivalent DYNAP-CNN layer configuration. Details of how to use the sinabs-dynapcnn interact with your designed SNNs, please visit tutorial\n",
    "\n",
    "\n",
    "\n",
    "#### Feature\n",
    "- Max input dimension for the layer: 128x128\n",
    "- Max output feature map size: 64x64\n",
    "- Max channel number: 1024\n",
    "- Weight resolution 8bit\n",
    "- Neuron State resolution 16bit\n",
    "- Max convolutional kernel size 16x16\n",
    "- Stride step:1,2,4,8\n",
    "- Padding: [0,1,2,3,4,5,6,7]\n",
    "- Sumpooling: 1x1, 2x2, 4x4\n",
    "- Fanout:2\n",
    "\n",
    "#### Internal Execution Order\n",
    "A single chip consists of __9__ configurable computing cores(layers), each layer can be regarded as a combination of (Conv2d Operation --> Spiking Activation --> Sumpooling). These computation has to be configured in exact equivalent execution order. Each layer can be flexiblely configured to be communicate with other layers.\n",
    "\n",
    "\n",
    "#### Async event-driven feature\n",
    "information communication with layers are only in \"Event based\" format, the layer process the \"incomming\" event only at whenever a layer recieves it. Each layer can be configured to set 1-2 destination to the other layer. \n",
    "\n",
    "\n",
    "#### Memory Constraints and Network Sizing\n",
    "Each layer has different memory constraints that split into kernel memory(for weight parameters) and neuron memory(spiking neuron states) as is shown below.  __Note:__ For the entire series of chips, dynapcnn/speck support precision of **8bit** int for kernel parameters and **16bit** int for neuron state precisions.\n",
    "\n",
    "![memoryconstrains](../_static/Overview/memory_constraints.png)\n",
    "\n",
    "<br />\n",
    "\n",
    "with a convolutional layer is defined as\n",
    "\n",
    "* $c$, stands for input channel number\n",
    "* $f$, output channel number\n",
    "* $k_x$ and $k_y$ kernel size\n",
    "\n",
    "The theoretial number of entries required for kernel memory $K_M$ is then\n",
    "\n",
    "$$K_M = cfk_{x}k_{y}$$\n",
    "\n",
    "The actual number of entries required in chip because of the address encoding scheme, the actual total memory requires $K_{MT}$ is then:\n",
    "\n",
    "$$K_{MT}=c \\cdot 2^{log_{2}^{k_{x}k_{y}} + log_{2}^{f}}$$\n",
    "\n",
    "The required neuron memory entries depends on the output feature map where define the input feature map size $c_{x}$, $c_{y}$, stride $s_{x}$, $s_{y}$, padding $p_{x}$, $p_{y}$.\n",
    "\n",
    "$$f_x = \\frac{c_{x}-k_{x}+2p_{x}}{s_{x}} + 1$$\n",
    "$$f_y = \\frac{c_{y}-k_{y}+2p_{y}}{s_{y}} + 1$$\n",
    "The actual neuron memory entries $N_{M}$ is then defined as:\n",
    "\n",
    "$$N_{M} = ff_{x}f_{y}$$\n",
    "\n",
    "\n",
    "Taking an example of convolutional layer\n",
    "\n",
    "    conv_layer = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "    \n",
    "Assume the input dimension of 64x64 we could obtain the output feature map size as:\n",
    "$$f_x = \\frac{64-3+2*1}{1} + 1 = 64$$\n",
    "$$f_y = \\frac{64-3+2*1}{1} + 1 = 64$$\n",
    "\n",
    "\n",
    "The actual kernel memory entries is calculated thus:\n",
    "$$K_{MT}=16 * 32 * 4 *4 = 8Ki$$\n",
    "The actual Neuron memory entries is then:\n",
    "$$N_{M} = 64*64*32 = 128Ki$$\n",
    "\n",
    "Where 128Ki neuron exceeds any available neuron memory contrains among 9 layers, thus this layer **CANNOT** be deployed on the chip\n",
    "\n",
    "#### Leak operation\n",
    "\n",
    "Each layer includes a leak generation block, which will update all the configured neuron states with provided leak values with a clock reference signal.**[tutorial on how to use leak feature]**\n",
    "\n",
    "#### Congestion banlancer\n",
    "In __latest devlopment kit(speck2e)__, each dynapcnn layer is equipped with a congestion banlancer upon its data path input. It is able to drops the incoming events at any time when the convolutional cores is overloaded in processing. \n",
    "\n",
    "\n",
    "#### Decimator\n",
    "* In __latest development kit(speck2e)__, each dynapcnn layer is equipped with a decimator block at its output data path. The decimator enables the user reduce the spike rate at the output of a convolution layer. When enabled, the decimator allows 1 spikes to be passed every N output spikes(N=[2,4,8,16,32,128,256,512]).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readout Layer\n",
    "\n",
    "The readout layer provides output data via the output serial interface. The time window where the readout window used is driven by an internal slow clock. The readout layer can be configured to have 1,16,32 times the provided clock cycle. 4 different addressing modes can be selected to assign input spikes to the readout layer to 15 available output classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal Slow clock\n",
    "\n",
    "**only avilable in latest speck2e**, a slow clock internally is used to support a number of time-cycle based features. \n",
    "\n",
    "* Leak clock, the DYNAPCNN layers including a leak operation that can operate on all the configured neuron states based on the clock setting.\n",
    "* DVS pre-processing filter: The DVS filter uses the slow clock as the time reference to update its internal states\n",
    "* Readout Layer: the readout layer uses the slow clock cycle as the moving average step to calculating the moving averages.\n",
    "\n",
    "Note: The slow clock is internally generated by dividing the internal DVS raw event rates, which not always gurantee to be accurate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Known dev-kit Bugs\n",
    "\n",
    "* Idx mapping error between the output DYNAP-CNN layer and readout block, for details see "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What network structure can I define?\n",
    "A: sinabs and sinabs-dynapcnn now only accepts auto converts the *nn.Sequential* structure. The skip and recurrent structure between DYNAPCNN layers are also support now by manually configuration.\n",
    "\n",
    "### 2. What kinds of neural network operation I can use in Speck/DYNAP-CNN?\n",
    "A: Currently we only support Conv2d, Avgpool, Sumpool, Linear, Flatten, as well as the IAF activation\n",
    "\n",
    "### 3. What execution order should I notice when I am implementing a sequential structure?\n",
    "A: You should be aware with the internal layer order. DYNAP-CNN techonology defines serveral layers that can be communicates each other. In a layer, the Convolution and Neuron activation must be implemented with **Conv-->IAF order-->pool(optional)** order. The cascaded convolution and neuron activation in a DYNAPCNN layer is not allowed.\n",
    "\n",
    "![dataflow](../_static/Overview/dataflow_layers.png)\n",
    "\n",
    "#### Ex1. Bad Case: Cascaded convlution\n",
    "```\n",
    "\n",
    "network = nn.sequential([\n",
    "                        nn.conv2d(),\n",
    "                        nn.conv2d(),\n",
    "                        IAFsqueeze(),\n",
    "                        ])\n",
    "                    \n",
    "```\n",
    "#### Ex2. Bad Case: None sequential\n",
    "```\n",
    "\n",
    "class Network:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.conv1 = nn.conv2d()\n",
    "        self.iaf = IAFsqueeze()\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.iaf(out)\n",
    "        return out\n",
    "                    \n",
    "```\n",
    "\n",
    "#### Ex3. Bad Case: Use unsupport operation\n",
    "\n",
    "```\n",
    "network = nn.sequential([\n",
    "                        nn.conv2d(),\n",
    "                        nn.BatchNorm2d(), # unspport in speck/dynapcnn\n",
    "                        IAFsqueeze(),\n",
    "                        ])\n",
    "```\n",
    "\n",
    "#### Ex3. Good Case: Use unsupport operation\n",
    "\n",
    "```\n",
    "network = nn.sequential([\n",
    "                        nn.conv2d(),\n",
    "                        IAFsqueeze(),\n",
    "                        nn.pool(),\n",
    "                        # up to here is using 1 dynapcnn layer\n",
    "                        nn.conv2d(),\n",
    "                        IAFsqueeze(),\n",
    "                        nn.Flatten(),\n",
    "                        nn.Linear(),\n",
    "                        IAFsqueeze(),\n",
    "                        # up to here is using 2 dynapcnn layer\n",
    "                        ])\n",
    "```\n",
    "\n",
    "\n",
    "### 4. What is the limination for network sizing?\n",
    "A: we introduced the neuron memory and kernel memory constraints in the design. Apart from these:\n",
    "* maximumlly using **9** dynapcnn layer\n",
    "* convolution channel number < **1024**\n",
    "* convolution kernel size < **16**\n",
    "* pool size = [1, 2, 4, 8]\n",
    "* if you are using readout layer, the number of output class should< **15**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
