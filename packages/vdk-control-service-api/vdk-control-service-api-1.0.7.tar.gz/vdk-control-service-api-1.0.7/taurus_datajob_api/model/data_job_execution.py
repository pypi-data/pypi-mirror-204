# coding: utf-8

"""
    Versatile Data Kit Control Service API

    The Data Jobs API of Versatile Data Kit Control Service. Data Jobs allows Data Engineers to implement automated pull ingestion (E in ELT) and batch data transformation into a database (T in ELT). See also https://github.com/vmware/versatile-data-kit/wiki/Introduction The API has resource-oriented URLs, JSON-encoded responses, and uses standard HTTP response codes, authentication, and verbs. The API enables creating, deploying, managing and executing Data Jobs in the runtime environment.<br> <br> ![](https://github.com/vmware/versatile-data-kit/wiki/vdk-data-job-lifecycle-state-diagram.png) <br> The API reflects the usual Data Job Development lifecycle:<br> <li> Create a new data job (webhook to further configure the job, e.g authorize its creation, setup permissions, etc). <li> Download keytab. Develop and run the data job locally. <li> Deploy the data job in cloud runtime environment to run on a scheduled basis. <br><br> If Authentication is enabled, pass OAuth2 access token in HTTP header 'Authorization: Bearer [access-token-here]' (https://datatracker.ietf.org/doc/html/rfc6750). <br The API promotes some best practices (inspired by https://12factor.net): <li> Explicitly declare and isolate dependencies. <li> Strict separation of configurations from code. Configurations vary substantially across deploys, code does not. <li> Separation between the build, release/deploy, and run stages. <li> Data Jobs are stateless and share-nothing processes. Any data that needs to be persisted must be stored in a stateful backing service (e.g IProperties). <li> Implementation is assumed to be atomic and idempotent - should be OK for a job to fail somewhere in the middle; subsequent restart should not cause data corruption. <li> Keep development, staging, and production as similar as possible. <br><br> <b>API Evolution</b><br> In the following sections, there are some terms that have a special meaning in the context of the APIs. <br><br> <li> <i>Stable</i> - The implementation of the API has been battle-tested (has been in production for some time). The API is a subject to semantic versioning model and will follow deprecation policy. <li> <i>Experimental</i> - May disappear without notice and is not a subject to semantic versioning. Implementation of the API is not considered stable nor well tested. Generally this is given to clients to experiment within testing environment. Must not be used in production. <li> <i>Deprecated</i> - API is expected to be removed within next one or two major version upgrade. The deprecation notice/comment will say when the API will be removed and what alternatives should be used instead.  # noqa: E501

    The version of the OpenAPI document: 1.0
    Generated by: https://openapi-generator.tech
"""

from datetime import date, datetime  # noqa: F401
import decimal  # noqa: F401
import functools  # noqa: F401
import io  # noqa: F401
import re  # noqa: F401
import typing  # noqa: F401
import typing_extensions  # noqa: F401
import uuid  # noqa: F401

import frozendict  # noqa: F401

from taurus_datajob_api import schemas  # noqa: F401


class DataJobExecution(
    schemas.DictSchema
):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.

    Executions of a Data Job
    """


    class MetaOapg:
        
        class properties:
            id = schemas.StrSchema
            job_name = schemas.StrSchema
            
            
            class status(
                schemas.EnumBase,
                schemas.StrSchema
            ):
            
            
                class MetaOapg:
                    enum_value_to_name = {
                        "submitted": "SUBMITTED",
                        "running": "RUNNING",
                        "succeeded": "SUCCEEDED",
                        "cancelled": "CANCELLED",
                        "skipped": "SKIPPED",
                        "user_error": "USER_ERROR",
                        "platform_error": "PLATFORM_ERROR",
                    }
                
                @schemas.classproperty
                def SUBMITTED(cls):
                    return cls("submitted")
                
                @schemas.classproperty
                def RUNNING(cls):
                    return cls("running")
                
                @schemas.classproperty
                def SUCCEEDED(cls):
                    return cls("succeeded")
                
                @schemas.classproperty
                def CANCELLED(cls):
                    return cls("cancelled")
                
                @schemas.classproperty
                def SKIPPED(cls):
                    return cls("skipped")
                
                @schemas.classproperty
                def USER_ERROR(cls):
                    return cls("user_error")
                
                @schemas.classproperty
                def PLATFORM_ERROR(cls):
                    return cls("platform_error")
            
            
            class type(
                schemas.EnumBase,
                schemas.StrSchema
            ):
            
            
                class MetaOapg:
                    enum_value_to_name = {
                        "manual": "MANUAL",
                        "scheduled": "SCHEDULED",
                    }
                
                @schemas.classproperty
                def MANUAL(cls):
                    return cls("manual")
                
                @schemas.classproperty
                def SCHEDULED(cls):
                    return cls("scheduled")
            start_time = schemas.DateTimeSchema
            end_time = schemas.DateTimeSchema
            started_by = schemas.StrSchema
            logs_url = schemas.StrSchema
            message = schemas.StrSchema
            op_id = schemas.StrSchema
        
            @staticmethod
            def deployment() -> typing.Type['DataJobDeployment']:
                return DataJobDeployment
            __annotations__ = {
                "id": id,
                "job_name": job_name,
                "status": status,
                "type": type,
                "start_time": start_time,
                "end_time": end_time,
                "started_by": started_by,
                "logs_url": logs_url,
                "message": message,
                "op_id": op_id,
                "deployment": deployment,
            }
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["job_name"]) -> MetaOapg.properties.job_name: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["status"]) -> MetaOapg.properties.status: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["type"]) -> MetaOapg.properties.type: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["start_time"]) -> MetaOapg.properties.start_time: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["end_time"]) -> MetaOapg.properties.end_time: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["started_by"]) -> MetaOapg.properties.started_by: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["logs_url"]) -> MetaOapg.properties.logs_url: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["message"]) -> MetaOapg.properties.message: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["op_id"]) -> MetaOapg.properties.op_id: ...
    
    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["deployment"]) -> 'DataJobDeployment': ...
    
    @typing.overload
    def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
    
    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "job_name", "status", "type", "start_time", "end_time", "started_by", "logs_url", "message", "op_id", "deployment", ], str]):
        # dict_instance[name] accessor
        return super().__getitem__(name)
    
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> typing.Union[MetaOapg.properties.id, schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["job_name"]) -> typing.Union[MetaOapg.properties.job_name, schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["status"]) -> typing.Union[MetaOapg.properties.status, schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["type"]) -> typing.Union[MetaOapg.properties.type, schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["start_time"]) -> typing.Union[MetaOapg.properties.start_time, schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["end_time"]) -> typing.Union[MetaOapg.properties.end_time, schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["started_by"]) -> typing.Union[MetaOapg.properties.started_by, schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["logs_url"]) -> typing.Union[MetaOapg.properties.logs_url, schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["message"]) -> typing.Union[MetaOapg.properties.message, schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["op_id"]) -> typing.Union[MetaOapg.properties.op_id, schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["deployment"]) -> typing.Union['DataJobDeployment', schemas.Unset]: ...
    
    @typing.overload
    def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
    
    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "job_name", "status", "type", "start_time", "end_time", "started_by", "logs_url", "message", "op_id", "deployment", ], str]):
        return super().get_item_oapg(name)
    

    def __new__(
        cls,
        *_args: typing.Union[dict, frozendict.frozendict, ],
        id: typing.Union[MetaOapg.properties.id, str, schemas.Unset] = schemas.unset,
        job_name: typing.Union[MetaOapg.properties.job_name, str, schemas.Unset] = schemas.unset,
        status: typing.Union[MetaOapg.properties.status, str, schemas.Unset] = schemas.unset,
        type: typing.Union[MetaOapg.properties.type, str, schemas.Unset] = schemas.unset,
        start_time: typing.Union[MetaOapg.properties.start_time, str, datetime, schemas.Unset] = schemas.unset,
        end_time: typing.Union[MetaOapg.properties.end_time, str, datetime, schemas.Unset] = schemas.unset,
        started_by: typing.Union[MetaOapg.properties.started_by, str, schemas.Unset] = schemas.unset,
        logs_url: typing.Union[MetaOapg.properties.logs_url, str, schemas.Unset] = schemas.unset,
        message: typing.Union[MetaOapg.properties.message, str, schemas.Unset] = schemas.unset,
        op_id: typing.Union[MetaOapg.properties.op_id, str, schemas.Unset] = schemas.unset,
        deployment: typing.Union['DataJobDeployment', schemas.Unset] = schemas.unset,
        _configuration: typing.Optional[schemas.Configuration] = None,
        **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
    ) -> 'DataJobExecution':
        return super().__new__(
            cls,
            *_args,
            id=id,
            job_name=job_name,
            status=status,
            type=type,
            start_time=start_time,
            end_time=end_time,
            started_by=started_by,
            logs_url=logs_url,
            message=message,
            op_id=op_id,
            deployment=deployment,
            _configuration=_configuration,
            **kwargs,
        )

from taurus_datajob_api.model.data_job_deployment import DataJobDeployment
